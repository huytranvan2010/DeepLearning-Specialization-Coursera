# 1. Intuition
Mô hình từ RNN -> GRU -> LSTM ngày càng phức tạp và tăng độ tính toán lên. Tuy nhiên để xác định được những unit phía sau cần phải xác định được uit phái trước. Transformer architectur ra đời giúp chúng ta thực hiện nhiều tính toán song song hay có thể xử lý cả câu tạo một thời điểm thay vì xử lý từng từ.
![1](images/Transfomer/1.png)

![2](images/Transfomer/2.png)

# 2. Self Attention

![3](images/Transfomer/3.png)

![4](images/Transfomer/4.png)

![5](images/Transfomer/5.png)

# 3. Multi-Head Attention

![6](images/Transfomer/6.png)
![7](images/Transfomer/7.png)
![8](images/Transfomer/8.png)
# 4. Transformer Network

![9](images/Transfomer/9.png)
![10](images/Transfomer/10.png)